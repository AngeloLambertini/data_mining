{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac59fd8",
   "metadata": {},
   "source": [
    "### PROBLEM 6.1.\n",
    "The file BostonHousing.csv contains\n",
    "information collected by the US Bureau of the Census concerning housing in the\n",
    "area of Boston, Massachusetts. The dataset includes information on 506 census\n",
    "housing tracts in the Boston area. The goal is to predict the median house price in\n",
    "new tracts based on information such as crime rate, pollution, and number of\n",
    "rooms. The dataset contains 13 predictors, and the outcome variable is the median\n",
    "house price (MEDV). Table 6.11 describes each of the predictors and the outcome\n",
    "variable.\n",
    "- a. Why should the data be partitioned into training and validation sets? What\n",
    "will the training set be used for? What will the validation set be used for?\n",
    "- b. Fit a multiple linear regression model to the median house price (MEDV) as a\n",
    "function of CRIM, CHAS, and RM. Write the equation for predicting the\n",
    "median house price from the predictors in the model.\n",
    "- c. Using the estimated regression model, what median house price is predicted\n",
    "for a tract in the Boston area that does not bound the Charles River, has a\n",
    "crime rate of 0.1, and where the average number of rooms per house is 6?\n",
    "- d. Reduce the number of predictors:\n",
    "-- i. Which predictors are likely to be measuring the same thing among the 13\n",
    "predictors? Discuss the relationships among INDUS, NOX, and TAX.\n",
    "-- ii. Compute the correlation table for the 12 numerical predictors and search\n",
    "for highly correlated pairs. These have potential redundancy and can\n",
    "cause multicollinearity. Choose which ones to remove based on this table.\n",
    "-- iii. Use three subset selection algorithms: backward, forward, and\n",
    "stepwise) to reduce the remaining predictors. Compute the validation\n",
    "performance for each of the three selected models. Compare RMSE,\n",
    "MAPE, and mean error, as well as histograms of the errors. Finally,\n",
    "describe the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12777da0",
   "metadata": {},
   "source": [
    "a) Partitioning the data into traning and validation sets is a crucial step in the process of developing a predictive model. The training set will be used to train and develop the model, the model will thus learn from the data how to tune its parameters. The validation set will then be used at the end of the training process to evaluate the model's performance and fine-tune its parameters by a repeated analysis of the validation set. It's important to have both parts so we can be sure to try our model on data that are new for it but that we know well and evaluate its predictive potential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef35c1c9",
   "metadata": {},
   "source": [
    "b) Fit a multiple linear regression model to the median house price (MEDV) as a\n",
    "function of CRIM, CHAS, and RM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "42d4497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, BayesianRidge\n",
    "import statsmodels.formula.api as sm\n",
    "import matplotlib.pylab as plt\n",
    "from dmba import regressionSummary, exhaustive_search\n",
    "from dmba import backward_elimination, forward_selection, stepwise_selection\n",
    "from dmba import adjusted_r2_score, AIC_score, BIC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "63432896",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_df = pd.read_csv(\"BostonHousing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "a37fdfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     PTRATIO  LSTAT  MEDV  CAT. MEDV  \n",
       "0       15.3   4.98  24.0          0  \n",
       "1       17.8   9.14  21.6          0  \n",
       "2       17.8   4.03  34.7          1  \n",
       "3       18.7   2.94  33.4          1  \n",
       "4       18.7   5.33  36.2          1  \n",
       "..       ...    ...   ...        ...  \n",
       "501     21.0   9.67  22.4          0  \n",
       "502     21.0   9.08  20.6          0  \n",
       "503     21.0   5.64  23.9          0  \n",
       "504     21.0   6.48  22.0          0  \n",
       "505     21.0   7.88  11.9          0  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "b7777b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "      <th>CAT. MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "      <td>0.166008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "      <td>0.372456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO       LSTAT  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534   12.653063   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946    7.141062   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    1.730000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000    6.950000   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000   11.360000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000   16.955000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000   37.970000   \n",
       "\n",
       "             MEDV   CAT. MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    22.532806    0.166008  \n",
       "std      9.197104    0.372456  \n",
       "min      5.000000    0.000000  \n",
       "25%     17.025000    0.000000  \n",
       "50%     21.200000    0.000000  \n",
       "75%     25.000000    0.000000  \n",
       "max     50.000000    1.000000  "
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1c501e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         float64\n",
       "ZN           float64\n",
       "INDUS        float64\n",
       "CHAS           int64\n",
       "NOX          float64\n",
       "RM           float64\n",
       "AGE          float64\n",
       "DIS          float64\n",
       "RAD            int64\n",
       "TAX            int64\n",
       "PTRATIO      float64\n",
       "LSTAT        float64\n",
       "MEDV         float64\n",
       "CAT. MEDV      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "db74c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['CRIM','CHAS', 'RM']\n",
    "outcome = 'MEDV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "87e3e8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CRIM  CHAS     RM\n",
      "0    0.00632     0  6.575\n",
      "1    0.02731     0  6.421\n",
      "2    0.02729     0  7.185\n",
      "3    0.03237     0  6.998\n",
      "4    0.06905     0  7.147\n",
      "..       ...   ...    ...\n",
      "501  0.06263     0  6.593\n",
      "502  0.04527     0  6.120\n",
      "503  0.06076     0  6.976\n",
      "504  0.10959     0  6.794\n",
      "505  0.04741     0  6.030\n",
      "\n",
      "[506 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bh_df[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "04bd883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bh_df[predictors]\n",
    "y = bh_df[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "f083a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training fit\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "train_pred = model.predict(train_X)\n",
    "train_results = pd.DataFrame({\n",
    "    'MEDV': train_y, \n",
    "    'predicted': train_pred, \n",
    "    'residual': train_y - train_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "1d06b0a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDV</th>\n",
       "      <th>predicted</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>22.008204</td>\n",
       "      <td>-5.908204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>17.2</td>\n",
       "      <td>19.893624</td>\n",
       "      <td>-2.693624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>28.6</td>\n",
       "      <td>26.371008</td>\n",
       "      <td>2.228992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>23.6</td>\n",
       "      <td>29.127448</td>\n",
       "      <td>-5.527448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>20.4</td>\n",
       "      <td>21.014621</td>\n",
       "      <td>-0.614621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MEDV  predicted  residual\n",
       "452  16.1  22.008204 -5.908204\n",
       "346  17.2  19.893624 -2.693624\n",
       "295  28.6  26.371008  2.228992\n",
       "88   23.6  29.127448 -5.527448\n",
       "322  20.4  21.014621 -0.614621"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "30019aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  -29.19346743060684\n",
      "  Predictors  coefficient\n",
      "0       CRIM    -0.240062\n",
      "1       CHAS     3.266817\n",
      "2         RM     8.325175\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0000\n",
      "       Root Mean Squared Error (RMSE) : 5.9666\n",
      "            Mean Absolute Error (MAE) : 3.9668\n",
      "          Mean Percentage Error (MPE) : -7.2747\n",
      "Mean Absolute Percentage Error (MAPE) : 22.5927\n"
     ]
    }
   ],
   "source": [
    "# print training coefficients\n",
    "print('intercept ', model.intercept_)\n",
    "print(pd.DataFrame({'Predictors': X.columns, 'coefficient': model.coef_}))\n",
    "\n",
    "# print training performance measures\n",
    "regressionSummary(train_y, model.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "62b238e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjusted r2 :  0.5507065652226033\n",
      "AIC :  1952.2995095916203\n",
      "BIC :  1970.8681736191672\n"
     ]
    }
   ],
   "source": [
    "#print training adj r, AIC, and BIC\n",
    "\n",
    "print('adjusted r2 : ', adjusted_r2_score(train_y, train_pred, model))\n",
    "print('AIC : ', AIC_score(train_y, train_pred, model))\n",
    "print('BIC : ', BIC_score(train_y, train_pred, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "1cde1a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Predicted  Actual   Residual\n",
      "307  27.813818    28.2   0.386182\n",
      "343  26.545802    23.9  -2.645802\n",
      "47   20.952301    16.6  -4.352301\n",
      "67   19.728016    22.0   2.271984\n",
      "362  14.563121    20.8   6.236879\n",
      "132  23.712901    23.0  -0.712901\n",
      "292  25.993767    27.9   1.906233\n",
      "31   21.031780    14.5  -6.531780\n",
      "218  23.589896    21.5  -2.089896\n",
      "90   24.217938    22.6  -1.617938\n",
      "481  25.631148    23.7  -1.931148\n",
      "344  28.026468    31.2   3.173532\n",
      "119  18.483361    19.3   0.816639\n",
      "66   18.973810    19.4   0.426190\n",
      "312  20.886242    19.4  -1.486242\n",
      "407  14.625108    27.9  13.274892\n",
      "376  22.490552    13.9  -8.590552\n",
      "225  43.317191    50.0   6.682809\n",
      "201  22.097993    24.1   2.002007\n",
      "147  11.247730    14.6   3.352270\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.1174\n",
      "       Root Mean Squared Error (RMSE) : 6.4125\n",
      "            Mean Absolute Error (MAE) : 4.4558\n",
      "          Mean Percentage Error (MPE) : -7.6160\n",
      "Mean Absolute Percentage Error (MAPE) : 23.1676\n"
     ]
    }
   ],
   "source": [
    "# use the model to make predictions on validation set\n",
    "\n",
    "model_pred = model.predict(valid_X)\n",
    "all_residuals = valid_y - model_pred\n",
    "\n",
    "result = pd.DataFrame({'Predicted': model_pred, 'Actual': valid_y,\n",
    "'Residual': valid_y - model_pred})\n",
    "print(result.head(20))\n",
    "\n",
    "# print performance measures (validation data)\n",
    "regressionSummary(valid_y, model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "5248c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# residuals histogram\n",
    "\n",
    "pd.DataFrame({'Residuals': all_residuals}).hist(bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "a8282eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients of the predictors are:  [-0.24006218  3.26681728  8.3251753 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"The coefficients of the predictors are: \", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "f08862f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept value is:  -29.19346743060684\n"
     ]
    }
   ],
   "source": [
    "print(\"The intercept value is: \", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f07e4",
   "metadata": {},
   "source": [
    "c) what median house price is predicted for a tract in the Boston area that does not bound the Charles River, has a crime rate of 0.1, and where the average number of rooms per house is 6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "87ee5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame([[0.1, 0, 6]], columns=['CRIM', 'CHAS', 'RM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "a2f8ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CRIM  CHAS  RM\n",
      "0   0.1     0   6\n"
     ]
    }
   ],
   "source": [
    "print(new_df[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "d05d85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "02e9ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.73357813] 2\n"
     ]
    }
   ],
   "source": [
    "# Use predict() to make predictions on a new set\n",
    "new_df_pred = model.predict(new_df)\n",
    "print(new_df_pred, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db713c29",
   "metadata": {},
   "source": [
    "<b>The median house price for the indicated values, based on our model, is $ 20,733.58</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b2a1b",
   "metadata": {},
   "source": [
    "d - I) Between the 13 predictors, NOX and AGE are likely to be measuring the same part of variation since old buildings are usually more polluting than new buildings and an increase in the average age should imply an increase in the consentration of nitric oxide. Also INDUS and NOX are probaby measuring the same thing since the concentration of nitric oxide depends highly on the concentration of industries in the area. Regarding the relationship among INDUS, NOX and TAX, the first 2 variables should be highly positive correlated and each of them should be positive correlated with TAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bced7ec",
   "metadata": {},
   "source": [
    "d - II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "eda6fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "9a1cd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh2_df = bh_df.loc[:, bh_df.columns.drop(['MEDV', 'CAT. MEDV'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "2e2fd7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = bh2_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908175b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def highlight_cells(val):\n",
    "    color = 'yellow' if (val > 0.7 and val != 1) or val < -0.7 else ''\n",
    "    return 'background-color: {}'.format(color)\n",
    "\n",
    "corr.style.applymap(highlight_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', ax = ax)\n",
    "plt.title('Correlation Heatmap with Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c916de",
   "metadata": {},
   "source": [
    "From the correlation table and heatmap we can see that we have 4 couples of variables with a strong positive correlation (>0.7) and 3 with a strong negative correlation (<-0.7). Based on this table, the variables that could be removed are: DIS (because it has a high correlation with 3 other variables and doesn't add much information to tour analysis), TAX (since it's highly correlated with 2 other variables, and AGE (since it's higlhy correlated with NOX)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21bfd2",
   "metadata": {},
   "source": [
    "d - III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['CRIM','ZN', 'INDUS','CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'LSTAT']\n",
    "X = bh_df[predictors]\n",
    "y = bh_df[outcome]\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b77c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward elimination\n",
    "\n",
    "def train_model(variables):\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "\n",
    "allVariables = train_X.columns\n",
    "best_model, best_variables = backward_elimination(allVariables, train_model, score_model, verbose=True)\n",
    "\n",
    "print(best_variables)\n",
    "\n",
    "regressionSummary(valid_y, best_model.predict(valid_X[best_variables]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e317b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward elimination validation errors histogram\n",
    "\n",
    "bh_df_pred = best_model.predict(valid_X[best_variables])\n",
    "all_residuals = valid_y - bh_df_pred\n",
    "\n",
    "all_residuals.plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward elimination\n",
    "\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [train_y.mean()] * len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "\n",
    "best_model, best_variables = forward_selection(train_X.columns, train_model, score_model, verbose=True)\n",
    "\n",
    "print(best_variables)\n",
    "\n",
    "regressionSummary(valid_y, best_model.predict(valid_X[best_variables]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d27f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward elimination validation errors histogram\n",
    "\n",
    "bh_df_pred = best_model.predict(valid_X[best_variables])\n",
    "all_residuals = valid_y - bh_df_pred\n",
    "\n",
    "all_residuals.plot(kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdbdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stepwise elimination\n",
    "\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [train_y.mean()] * len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "\n",
    "best_model, best_variables = stepwise_selection(train_X.columns, train_model, score_model, verbose=True)\n",
    "\n",
    "print(best_variables)\n",
    "\n",
    "regressionSummary(valid_y, best_model.predict(valid_X[best_variables]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915de7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stepwise elimination validation errors histogram\n",
    "\n",
    "bh_df_pred = best_model.predict(valid_X[best_variables])\n",
    "all_residuals = valid_y - bh_df_pred\n",
    "\n",
    "all_residuals.plot(kind='hist')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e076d",
   "metadata": {},
   "source": [
    "From the regression summary of each of the three models (created with the three different subset selection algorithms, which dropped the same two variables - AGE and INDUS), we can see that RMSE, MAPE, and ME are the same for all the models, consequently all the three histograms show the same distribution and values, from which we can individuate the presence of one or a few upper outliers which will need special attention and further investigation. In this case, we can conclude that all the three models have the same performance in predicting the median house price in the area of Boston and there is no best model between them. \n",
    "Overall, the Mean Error of our models, -0.039, indicates that our model is on average underpredicting the median house price; the MAPE of our models, 16.97, indicates that the accuracy of the models is low but still acceptable (it's usually considered low but acceptable between 10.00 and 25.00); the RMSE is 5.08 (x1000$)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
